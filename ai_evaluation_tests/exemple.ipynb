{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de test pour lancer de manière guidée de nombreux tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decouple import config\n",
    "\n",
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import needed for the pre-processing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All model import\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "RANDOM_STATE = 42\n",
    "SEED = 42\n",
    "URI = config(\"URI\")\n",
    "EXPERIMENT_ID = 415539499946844786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "DATA_PATH = \"../../data/solar_weather.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_REGRESSION = [\"ridge\", \"mlp_regressor\", \"knn_regressor\", \"light_gmb_poisson\", \"adaboost\"]\n",
    "MODEL_FUNCTION = {\n",
    "    # regression\n",
    "    \"ridge\": Ridge(),\n",
    "    \"mlp_regressor\": MLPRegressor(),\n",
    "    \"light_gmb_poisson\": HistGradientBoostingRegressor(loss=\"poisson\"),\n",
    "    \"adaboost\": AdaBoostRegressor(),\n",
    "    \"knn_regressor\": KNeighborsRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get and pre-process the datas\n",
    "def get_data(frac: float = 1.0) -> Tuple:\n",
    "    \"\"\"Function used for the weather dataset\"\"\"\n",
    "\n",
    "    data = pd.read_csv(DATA_PATH).sample(frac=frac, random_state=RANDOM_STATE)\n",
    "    target_column = \"Energy delta[Wh]\"\n",
    "    data = data.drop([\"Time\"], axis=1)\n",
    "    # No features to modify\n",
    "\n",
    "    iforest = IsolationForest(contamination=0.1, random_state=RANDOM_STATE)\n",
    "    outliers = iforest.fit_predict(data)\n",
    "    clean_data = data[(outliers != -1)]\n",
    "\n",
    "    # we normalize\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    clean_array = min_max_scaler.fit_transform(clean_data)\n",
    "    clean_data = pd.DataFrame(clean_array, columns=clean_data.keys())\n",
    "\n",
    "    data_values = clean_data.drop([target_column], axis=1)\n",
    "    data_target = clean_data[target_column]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data_values, data_target, test_size=0.3, random_state=RANDOM_STATE\n",
    "    )\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hennecarta\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = get_data(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_preparation():\n",
    "    mlflow.set_tracking_uri(URI)\n",
    "    experiment_id = mlflow.set_experiment(experiment_id=EXPERIMENT_ID)\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "def log_params(data_train, data_test, model_name) -> None:\n",
    "    mlflow.log_param(\"nb_features\", data_train[0].shape[1])\n",
    "    mlflow.log_param(\"nb_samples_train\", data_train[0].shape[0])\n",
    "    mlflow.log_param(\"nb_samples_test\", data_test[0].shape[0])\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "\n",
    "\n",
    "def launch_model(run_name, experiment_id, data_train: tuple, data_test: tuple, model):\n",
    "    mlflow.start_run(run_name=run_name, experiment_id=experiment_id)\n",
    "    log_params(data_train, data_test, model)\n",
    "    model = MODEL_FUNCTION[model]\n",
    "    model.fit(data_train[0], data_train[1])\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    eval_data = data_test[0]\n",
    "    eval_data[\"label\"] = data_test[1]\n",
    "    mlflow.evaluate(\n",
    "        model=model_uri,\n",
    "        data=eval_data,\n",
    "        targets=\"label\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=\"default\",\n",
    "    )\n",
    "    print(f\"Model saved in run {mlflow.active_run().info.run_uuid}\")\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    size = [1]\n",
    "    experiment_id = mlflow_preparation()\n",
    "    # for data in DATA_REGRESSION:\n",
    "    for frac in size:\n",
    "        print(\"data loading\")\n",
    "        data_train, data_test = get_data(frac)\n",
    "        print(\"data loaded\")\n",
    "        for model in MODEL_REGRESSION:\n",
    "            run_name = model + \"-Test-\" + str(frac)\n",
    "            print(run_name + \" start\")\n",
    "            launch_model(run_name, EXPERIMENT_ID, data_train, data_test, model)\n",
    "            print(run_name + \" over\")\n",
    "    print(mlflow.get_tracking_uri())\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but IsolationForest was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "ridge-Test-0.1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/23 14:42:33 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/23 14:42:33 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Linear is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2023/05/23 14:42:33 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'Ridge' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run bb5da16b977544a9bb6bd848b6d4726e\n",
      "ridge-Test-0.1 over\n",
      "mlp_regressor-Test-0.1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/23 14:42:47 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/23 14:42:47 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: MLPRegressor()'). Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 7e9e21ea28de4de68b54b8511f4bf3ff\n",
      "mlp_regressor-Test-0.1 over\n",
      "knn_regressor-Test-0.1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/23 14:42:58 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/23 14:42:58 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: KNeighborsRegressor()'). Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 63ba824f3d6147708f4a596501e2280e\n",
      "knn_regressor-Test-0.1 over\n",
      "light_gmb_poisson-Test-0.1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/23 14:43:09 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/23 14:43:09 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "2023/05/23 14:43:13 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: ExplainerError('Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was -3.911619, while the model output was -4.383185. If this difference is acceptable you can set check_additivity=False to disable this check.'). Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 23fd91d993b74be6bfd81073057d4e76\n",
      "light_gmb_poisson-Test-0.1 over\n",
      "adaboost-Test-0.1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/23 14:43:23 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/05/23 14:43:23 WARNING mlflow.models.evaluation.default_evaluator: Shap evaluation failed. Reason: TypeError('The passed model is not callable and cannot be analyzed directly with the given masker! Model: AdaBoostRegressor()'). Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 06c44fb37ec149ccbeb75382b86e9c32\n",
      "adaboost-Test-0.1 over\n",
      "http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
